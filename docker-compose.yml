version: '3.9'

services:
  db:
    image: postgres
    container_name: postgres_container
    environment:
      POSTGRES_DB: UserTaskDataBase
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin
    volumes:
      - postgres_data:/var/lib/postgresql/data # Making it more generic # - "/home/emumba/Documents/Docker Postgres Container Data:/var/lib/postgresql/data/"
      - ./db_backup.dump:/docker-entrypoint-initdb.d/db_backup.dump # Specifying our data dump, to be loaded
      - ./pg_restore_script.sh:/docker-entrypoint-initdb.d/init.sh  # The init will load our data dump only once, on initialization of the container
    networks:
      - app-network    # Both postgres container and Django container will share the same Docker network so that they may communicate with each other

  redis:
      image: redis:7
      container_name: redis_container
      restart: always
      networks:
        - app-network # Redis will also share the same Docker network so that it may communicate with Django container

  celery:
    build: .
    command: celery -A DjangoEmumbaTrainingProject worker --loglevel=info
    volumes:
      - .:/app
    env_file:        # We have specified our env file, now we can even override it's values. So, we will override the postgres database credentails according to our container credentials
      - .env
    environment:                # <-- overrides .env value
      POSTGRES_DB: mydb_from_yml
      DB_NAME: UserTaskDataBase
      DB_USER: postgres
      DB_PASSWORD: admin
      DB_HOST: postgres_container   # Now it is no longer localhost but rather we will use the name of the database container, and we can do this because both the Django and database are on the same docker network
      DB_PORT: 5432    # Basically our Django container can access this port of the postgres container using the postgres container name because they are both on the same docker network
      REDIS_HOST: redis_container  # To allow Django to reach Redis
      REDIS_PORT: 6379             # Default Redis port
    depends_on:
      - db
      - redis
    networks:
      - app-network

  celery-beat:
    build: .
    command: celery -A DjangoEmumbaTrainingProject beat --loglevel=info
    volumes:
      - .:/app
    env_file:        # We have specified our env file, now we can even override it's values. So, we will override the postgres database credentails according to our container credentials
      - .env
    environment:                # <-- overrides .env value
      POSTGRES_DB: mydb_from_yml
      DB_NAME: UserTaskDataBase
      DB_USER: postgres
      DB_PASSWORD: admin
      DB_HOST: postgres_container   # Now it is no longer localhost but rather we will use the name of the database container, and we can do this because both the Django and database are on the same docker network
      DB_PORT: 5432    # Basically our Django container can access this port of the postgres container using the postgres container name because they are both on the same docker network
      REDIS_HOST: redis_container  # To allow Django to reach Redis
      REDIS_PORT: 6379             # Default Redis port
    depends_on:
      - db
      - redis
    networks:
      - app-network


  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: django_container
    #volumes:        # Keep these 2 lines commented in production. Why? Because what it is doing is binding our current directory (the one having the source code) to the container. Sp, when the 
    #  - .:/app      # - Container runs, it will override the code we copied in it (in the Dockerfile) and instead use the source code in our machine/host. So, if we edit the code in the machine, the container will reflect this and restart the django. It is good for development/testing but not recommended for production/deployment.
    ports:
      - "8000:8000"  # Expose to host: http://localhost:8000
    env_file:        # We have specified our env file, now we can even override it's values. So, we will override the postgres database credentails according to our container credentials
      - .env
    environment:                # <-- overrides .env value
      POSTGRES_DB: mydb_from_yml  
      DB_NAME: UserTaskDataBase
      DB_USER: postgres
      DB_PASSWORD: admin
      DB_HOST: postgres_container   # Now it is no longer localhost but rather we will use the name of the database container, and we can do this because both the Django and database are on the same docker network
      DB_PORT: 5432    # Basically our Django container can access this port of the postgres container using the postgres container name because they are both on the same docker network
      REDIS_HOST: redis_container  # To allow Django to reach Redis
      REDIS_PORT: 6379             # Default Redis port
    depends_on:
      - db
      - redis
    networks:
      - app-network  # Both postgres container and Django container will share the same Docker network so that they may communicate with each other
    command: >
      sh -c "python manage.py migrate && python manage.py migrate django_celery_beat && python manage.py runserver 0.0.0.0:8000"

# Defining the network
networks:
  app-network:

# This is a docker managed volume. Using it and mapping it to our postgres data to make our deployment more generic
# So, anywhere we may run this docker compose file, this volume will be made, maintained and linked to the container by docker
# This line in the volumes: - postgres_data:/var/lib/postgresql/data is linking it to the container postgres_container
volumes:
  postgres_data:
